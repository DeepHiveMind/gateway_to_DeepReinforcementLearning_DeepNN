{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizer ",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepHiveMind/80-days-study-guide-to-Deep-Learning-Reinforced-Learning-and-Deep-Reinforced-Learning/blob/master/Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rqV5S4o2bg55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Dec 26 08:10:53 2018\n",
        "\n",
        "@author: RAM G\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "tf.enable_eager_execution()\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "np.random.seed(101) \n",
        "tf.set_random_seed(101) \n",
        "# Genrating random linear data \n",
        "# There will be 50 data points ranging from 0 to 50 \n",
        "import numpy as np\n",
        "x = np.linspace(0, 50, 50) \n",
        "y = np.linspace(0, 50, 50) \n",
        "\n",
        "# Adding noise to the random linear data \n",
        "x += np.random.uniform(-4, 4, 50) \n",
        "y += np.random.uniform(-4, 4, 50) \n",
        "\n",
        "n = len(x) # Number of data points \n",
        "X = tf.placeholder(\"float\") \n",
        "Y = tf.placeholder(\"float\") \n",
        "W = tf.Variable(np.random.randn(), name = \"W\") \n",
        "b = tf.Variable(np.random.randn(), name = \"b\") \n",
        "learning_rate = 0.01\n",
        "training_epochs = 1000\n",
        "# Hypothesis \n",
        "y_pred = tf.add(tf.multiply(X, W), b) \n",
        "\n",
        "# Mean Squared Error Cost Function \n",
        "cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n) \n",
        "\n",
        "# Gradient Descent Optimizer \n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) \n",
        "\n",
        "# Global Variables Initializer \n",
        "init = tf.global_variables_initializer() \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}